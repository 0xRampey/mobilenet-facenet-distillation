{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, I'll load the required data and setup keras settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# use non standard flow_from_directory\n",
    "from utils.image_preprocessing_ver2 import ImageDataGenerator\n",
    "# it outputs y_batch that contains embeddings\n",
    "\n",
    "from utils.mobilenet import get_mobilenet\n",
    "import keras\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from keras.models import Model\n",
    "from keras import optimizers\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.layers import Lambda, concatenate, Activation\n",
    "from keras.losses import categorical_crossentropy as logloss\n",
    "from keras.metrics import categorical_accuracy, top_k_categorical_accuracy\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Activation, GlobalAveragePooling2D, Dropout, Dense, Input\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_dir = 'data/face_emb_logits/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_logits = np.load(logit_dir + 'train_set.npy')[()]\n",
    "val_logits = np.load(logit_dir + 'test_set.npy')[()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/home/prudhvi/Desktop/Datasets/lfw/lfw_mtcnn_160_split/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixed_image_stand(image):\n",
    "    return (tf.cast(image, tf.float32) - 127.5)/128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12020 images belonging to 1 classes.\n",
      "Found 1213 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = ImageDataGenerator(\n",
    "    data_format='channels_last',\n",
    "    preprocessing_function = fixed_image_stand\n",
    ")\n",
    "\n",
    "test_generator = ImageDataGenerator(\n",
    "    data_format='channels_last',\n",
    "    preprocessing_function = fixed_image_stand\n",
    ")\n",
    "\n",
    "# note: i'm also passing dicts of logits\n",
    "train_generator = train_generator.flow_from_directory(\n",
    "    data_dir + 'train/', train_logits,\n",
    "    target_size=(160, 160),\n",
    "    batch_size=64,\n",
    "    class_mode = 'embedding',\n",
    ")\n",
    "\n",
    "val_generator = test_generator.flow_from_directory(\n",
    "    data_dir + 'test', val_logits,\n",
    "    target_size=(160, 160),\n",
    "    batch_size=64,\n",
    "    class_mode = 'embedding',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create your Mobilenet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 160, 160, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)    (None, 162, 162, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 80, 80, 32)        864       \n",
      "_________________________________________________________________\n",
      "conv1_bn (BatchNormalization (None, 80, 80, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv1_relu (Activation)      (None, 80, 80, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_pad_1 (ZeroPadding2D)   (None, 82, 82, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_1 (DepthwiseConv2D)  (None, 80, 80, 32)        288       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_bn (BatchNormaliza (None, 80, 80, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_relu (Activation)  (None, 80, 80, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_1 (Conv2D)           (None, 80, 80, 64)        2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_1_bn (BatchNormaliza (None, 80, 80, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_pw_1_relu (Activation)  (None, 80, 80, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_pad_2 (ZeroPadding2D)   (None, 82, 82, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_2 (DepthwiseConv2D)  (None, 40, 40, 64)        576       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_bn (BatchNormaliza (None, 40, 40, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_relu (Activation)  (None, 40, 40, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_2 (Conv2D)           (None, 40, 40, 128)       8192      \n",
      "_________________________________________________________________\n",
      "conv_pw_2_bn (BatchNormaliza (None, 40, 40, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_2_relu (Activation)  (None, 40, 40, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_3 (ZeroPadding2D)   (None, 42, 42, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_3 (DepthwiseConv2D)  (None, 40, 40, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_3_bn (BatchNormaliza (None, 40, 40, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_3_relu (Activation)  (None, 40, 40, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_3 (Conv2D)           (None, 40, 40, 128)       16384     \n",
      "_________________________________________________________________\n",
      "conv_pw_3_bn (BatchNormaliza (None, 40, 40, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_3_relu (Activation)  (None, 40, 40, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_4 (ZeroPadding2D)   (None, 42, 42, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_4 (DepthwiseConv2D)  (None, 20, 20, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_4_bn (BatchNormaliza (None, 20, 20, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_4_relu (Activation)  (None, 20, 20, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_4 (Conv2D)           (None, 20, 20, 256)       32768     \n",
      "_________________________________________________________________\n",
      "conv_pw_4_bn (BatchNormaliza (None, 20, 20, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_4_relu (Activation)  (None, 20, 20, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_5 (ZeroPadding2D)   (None, 22, 22, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_5 (DepthwiseConv2D)  (None, 20, 20, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_bn (BatchNormaliza (None, 20, 20, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_relu (Activation)  (None, 20, 20, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_5 (Conv2D)           (None, 20, 20, 256)       65536     \n",
      "_________________________________________________________________\n",
      "conv_pw_5_bn (BatchNormaliza (None, 20, 20, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_5_relu (Activation)  (None, 20, 20, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_6 (ZeroPadding2D)   (None, 22, 22, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_6 (DepthwiseConv2D)  (None, 10, 10, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_bn (BatchNormaliza (None, 10, 10, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_relu (Activation)  (None, 10, 10, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_6 (Conv2D)           (None, 10, 10, 512)       131072    \n",
      "_________________________________________________________________\n",
      "conv_pw_6_bn (BatchNormaliza (None, 10, 10, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_6_relu (Activation)  (None, 10, 10, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_7 (ZeroPadding2D)   (None, 12, 12, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_7 (DepthwiseConv2D)  (None, 10, 10, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_bn (BatchNormaliza (None, 10, 10, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_relu (Activation)  (None, 10, 10, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_7 (Conv2D)           (None, 10, 10, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_7_bn (BatchNormaliza (None, 10, 10, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_7_relu (Activation)  (None, 10, 10, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_8 (ZeroPadding2D)   (None, 12, 12, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_8 (DepthwiseConv2D)  (None, 10, 10, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_bn (BatchNormaliza (None, 10, 10, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_relu (Activation)  (None, 10, 10, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_8 (Conv2D)           (None, 10, 10, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_8_bn (BatchNormaliza (None, 10, 10, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_8_relu (Activation)  (None, 10, 10, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_9 (ZeroPadding2D)   (None, 12, 12, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_9 (DepthwiseConv2D)  (None, 10, 10, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_bn (BatchNormaliza (None, 10, 10, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_relu (Activation)  (None, 10, 10, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_9 (Conv2D)           (None, 10, 10, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_9_bn (BatchNormaliza (None, 10, 10, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_9_relu (Activation)  (None, 10, 10, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_10 (ZeroPadding2D)  (None, 12, 12, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_10 (DepthwiseConv2D) (None, 10, 10, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_bn (BatchNormaliz (None, 10, 10, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_relu (Activation) (None, 10, 10, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_10 (Conv2D)          (None, 10, 10, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_10_bn (BatchNormaliz (None, 10, 10, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_10_relu (Activation) (None, 10, 10, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_11 (ZeroPadding2D)  (None, 12, 12, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_11 (DepthwiseConv2D) (None, 10, 10, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_bn (BatchNormaliz (None, 10, 10, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_relu (Activation) (None, 10, 10, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_11 (Conv2D)          (None, 10, 10, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_11_bn (BatchNormaliz (None, 10, 10, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_11_relu (Activation) (None, 10, 10, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_12 (ZeroPadding2D)  (None, 12, 12, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_12 (DepthwiseConv2D) (None, 5, 5, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_bn (BatchNormaliz (None, 5, 5, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_relu (Activation) (None, 5, 5, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_12 (Conv2D)          (None, 5, 5, 1024)        524288    \n",
      "_________________________________________________________________\n",
      "conv_pw_12_bn (BatchNormaliz (None, 5, 5, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_12_relu (Activation) (None, 5, 5, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_pad_13 (ZeroPadding2D)  (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_13 (DepthwiseConv2D) (None, 5, 5, 1024)        9216      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_bn (BatchNormaliz (None, 5, 5, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_relu (Activation) (None, 5, 5, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_13 (Conv2D)          (None, 5, 5, 1024)        1048576   \n",
      "_________________________________________________________________\n",
      "conv_pw_13_bn (BatchNormaliz (None, 5, 5, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_13_relu (Activation) (None, 5, 5, 1024)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_6 ( (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "lambda_6 (Lambda)            (None, 512)               0         \n",
      "=================================================================\n",
      "Total params: 3,753,664\n",
      "Trainable params: 2,113,024\n",
      "Non-trainable params: 1,640,640\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def get_mobilenet(input_size = 160, alpha = 1 ):\n",
    "    \n",
    "    input_shape = (input_size, input_size, 3)\n",
    "    base_model = MobileNet(\n",
    "        include_top=False, weights='imagenet', \n",
    "        input_shape=input_shape, alpha=alpha\n",
    "    )\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "#     x = Dropout(0.25)(x)\n",
    "#     logits = Dense(512, kernel_regularizer = regularizers.l2(0.001))(x)\n",
    "    logits = Dense(512)(x)\n",
    "    l2_norm = Lambda(lambda  x: K.l2_normalize(x,axis=1))(logits)\n",
    "    model = Model(base_model.input, l2_norm)\n",
    "    \n",
    "    for layer in model.layers[:-13]:\n",
    "        layer.trainable = False\n",
    "    return model\n",
    "\n",
    "model = get_mobilenet()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_loss(y_true, y_pred):    \n",
    "    \n",
    "    return K.mean(K.sum(K.square(y_true - y_pred), axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.compile(\n",
    "    optimizer=optimizers.SGD(lr=1e-1, momentum=0.9, nesterov=True), #SGD has the best generalization capability\n",
    "#     optimizer = optimizers.RMSprop(lr=1e-5),\n",
    "    loss=embedding_loss, \n",
    "    metrics=[embedding_loss]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras/callbacks.py:999: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "  warnings.warn('`epsilon` argument is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "400/400 [==============================] - 7644s 19s/step - loss: 1.1787 - embedding_loss: 1.1787 - val_loss: 1.8890 - val_embedding_loss: 1.8890\n",
      "Epoch 2/30\n",
      " 55/400 [===>..........................] - ETA: 14:43 - loss: 0.9492 - embedding_loss: 0.9492"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (0.702481). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 57/400 [===>..........................] - ETA: 14:25 - loss: 0.9473 - embedding_loss: 0.9473"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (0.438212). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 809s 2s/step - loss: 0.8569 - embedding_loss: 0.8569 - val_loss: 1.7901 - val_embedding_loss: 1.7901\n",
      "Epoch 3/30\n",
      "400/400 [==============================] - 170s 424ms/step - loss: 0.7082 - embedding_loss: 0.7082 - val_loss: 1.9012 - val_embedding_loss: 1.9012\n",
      "Epoch 4/30\n",
      "400/400 [==============================] - 135s 338ms/step - loss: 0.5910 - embedding_loss: 0.5910 - val_loss: 1.8225 - val_embedding_loss: 1.8225\n",
      "Epoch 5/30\n",
      "400/400 [==============================] - 112s 279ms/step - loss: 0.4814 - embedding_loss: 0.4814 - val_loss: 1.8605 - val_embedding_loss: 1.8605\n",
      "Epoch 6/30\n",
      "400/400 [==============================] - 189s 473ms/step - loss: 0.4532 - embedding_loss: 0.4532 - val_loss: 1.8599 - val_embedding_loss: 1.8599\n",
      "Epoch 7/30\n",
      "400/400 [==============================] - 159s 397ms/step - loss: 0.4382 - embedding_loss: 0.4382 - val_loss: 1.8471 - val_embedding_loss: 1.8471\n",
      "Epoch 8/30\n",
      "400/400 [==============================] - 183s 459ms/step - loss: 0.4344 - embedding_loss: 0.4344 - val_loss: 1.8538 - val_embedding_loss: 1.8538\n",
      "Epoch 9/30\n",
      "400/400 [==============================] - 275s 687ms/step - loss: 0.4338 - embedding_loss: 0.4338 - val_loss: 1.8525 - val_embedding_loss: 1.8525\n",
      "Epoch 10/30\n",
      "400/400 [==============================] - 254s 634ms/step - loss: 0.4330 - embedding_loss: 0.4330 - val_loss: 1.8514 - val_embedding_loss: 1.8514\n",
      "Epoch 11/30\n",
      "400/400 [==============================] - 154s 385ms/step - loss: 0.4331 - embedding_loss: 0.4331 - val_loss: 1.8534 - val_embedding_loss: 1.8534\n",
      "Epoch 12/30\n",
      "400/400 [==============================] - 185s 462ms/step - loss: 0.4325 - embedding_loss: 0.4325 - val_loss: 1.8552 - val_embedding_loss: 1.8552\n",
      "Epoch 13/30\n",
      "400/400 [==============================] - 145s 363ms/step - loss: 0.4331 - embedding_loss: 0.4331 - val_loss: 1.8545 - val_embedding_loss: 1.8545\n",
      "Epoch 14/30\n",
      "400/400 [==============================] - 146s 366ms/step - loss: 0.4321 - embedding_loss: 0.4321 - val_loss: 1.8504 - val_embedding_loss: 1.8504\n",
      "Epoch 15/30\n",
      "400/400 [==============================] - 153s 384ms/step - loss: 0.4322 - embedding_loss: 0.4322 - val_loss: 1.8515 - val_embedding_loss: 1.8515\n",
      "Epoch 16/30\n",
      "400/400 [==============================] - 144s 360ms/step - loss: 0.4327 - embedding_loss: 0.4327 - val_loss: 1.8526 - val_embedding_loss: 1.8526\n",
      "Epoch 17/30\n",
      "400/400 [==============================] - 176s 440ms/step - loss: 0.4329 - embedding_loss: 0.4329 - val_loss: 1.8542 - val_embedding_loss: 1.8542\n",
      "Epoch 18/30\n",
      "400/400 [==============================] - 210s 525ms/step - loss: 0.4329 - embedding_loss: 0.4329 - val_loss: 1.8519 - val_embedding_loss: 1.8519\n",
      "Epoch 19/30\n",
      "400/400 [==============================] - 172s 429ms/step - loss: 0.4325 - embedding_loss: 0.4325 - val_loss: 1.8537 - val_embedding_loss: 1.8537\n",
      "Epoch 20/30\n",
      "400/400 [==============================] - 167s 418ms/step - loss: 0.4321 - embedding_loss: 0.4321 - val_loss: 1.8536 - val_embedding_loss: 1.8536\n",
      "Epoch 21/30\n",
      "400/400 [==============================] - 208s 519ms/step - loss: 0.4321 - embedding_loss: 0.4321 - val_loss: 1.8534 - val_embedding_loss: 1.8534\n",
      "Epoch 22/30\n",
      "400/400 [==============================] - 188s 471ms/step - loss: 0.4330 - embedding_loss: 0.4330 - val_loss: 1.8553 - val_embedding_loss: 1.8553\n",
      "Epoch 23/30\n",
      "400/400 [==============================] - 182s 455ms/step - loss: 0.4329 - embedding_loss: 0.4329 - val_loss: 1.8520 - val_embedding_loss: 1.8520\n",
      "Epoch 24/30\n",
      "400/400 [==============================] - 190s 475ms/step - loss: 0.4321 - embedding_loss: 0.4321 - val_loss: 1.8519 - val_embedding_loss: 1.8519\n",
      "Epoch 25/30\n",
      "400/400 [==============================] - 190s 476ms/step - loss: 0.4329 - embedding_loss: 0.4329 - val_loss: 1.8511 - val_embedding_loss: 1.8511\n",
      "Epoch 26/30\n",
      "400/400 [==============================] - 244s 609ms/step - loss: 0.4326 - embedding_loss: 0.4326 - val_loss: 1.8509 - val_embedding_loss: 1.8509\n",
      "Epoch 27/30\n",
      "400/400 [==============================] - 222s 555ms/step - loss: 0.4321 - embedding_loss: 0.4321 - val_loss: 1.8541 - val_embedding_loss: 1.8541\n",
      "Epoch 28/30\n",
      "400/400 [==============================] - 153s 383ms/step - loss: 0.4326 - embedding_loss: 0.4326 - val_loss: 1.8514 - val_embedding_loss: 1.8514\n",
      "Epoch 29/30\n",
      "400/400 [==============================] - 160s 399ms/step - loss: 0.4328 - embedding_loss: 0.4328 - val_loss: 1.8523 - val_embedding_loss: 1.8523\n",
      "Epoch 30/30\n",
      "400/400 [==============================] - 183s 456ms/step - loss: 0.4332 - embedding_loss: 0.4332 - val_loss: 1.8507 - val_embedding_loss: 1.8507\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdd3096f0b8>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    train_generator, \n",
    "    steps_per_epoch=400, epochs=30, verbose=1,\n",
    "    callbacks=[\n",
    "        ReduceLROnPlateau(monitor='val_embedding_loss', factor=0.1, patience=2, epsilon=0.007)\n",
    "    ],\n",
    "    validation_data=val_generator, validation_steps=80, workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss/epoch plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdd305196d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "plt.plot(model.history.history['embedding_loss'], label='train');\n",
    "plt.plot(model.history.history['val_embedding_loss'], label='val');\n",
    "plt.legend();\n",
    "plt.xlabel('epoch');\n",
    "plt.ylabel('emb_loss');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export your model to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "K.set_learning_phase(0)  # all new operations will be in test mode from now on\n",
    "\n",
    "# serialize the model and get its weights, for quick re-building\n",
    "json_config = model.to_json()\n",
    "weights = model.get_weights()\n",
    "\n",
    "# re-build a model where the learning phase is now hard-coded to 0\n",
    "from keras.models import model_from_json\n",
    "new_model = model_from_json(json_config, {'relu6': keras.applications.mobilenet.mobilenet.relu6})\n",
    "new_model.set_weights(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 137 variables.\n",
      "Converted 137 variables to const ops.\n",
      "saved the freezed graph (ready for inference)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.framework import graph_util\n",
    "from tensorflow.python.framework import graph_io\n",
    "\n",
    "sess = K.get_session()\n",
    "constant_graph = graph_util.convert_variables_to_constants(sess, sess.graph.as_graph_def(), [new_model.output.op.name])\n",
    "graph_io.write_graph(constant_graph, './', 'train.pb', as_text=False)\n",
    "print('saved the freezed graph (ready for inference)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
