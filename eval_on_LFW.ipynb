{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipynb.fs #Boilerplate for import ipynb.fs #Boilerplate for ipynb botebooks as modules\n",
    "\n",
    "from utils import facenet\n",
    "import math\n",
    "from utils import lfw, tf_graph_viz\n",
    "# from .defs.Facenet_impl import get_face_embeddings\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn import metrics\n",
    "from scipy.optimize import brentq\n",
    "from scipy import interpolate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embeddings are calculated using the pairs from http://vis-www.cs.umass.edu/lfw/pairs.txt\n",
    "pairs_path = '/home/prudhvi/Desktop/Distillation/mobilenet-facenet-distillation/data/pairs.txt'\n",
    "pairs = lfw.read_pairs(pairs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"~/Desktop/Datasets/lfw/lfw_mtcnnpy_160\"\n",
    "# Get the paths for the corresponding images\n",
    "paths, actual_issame = lfw.get_paths(os.path.expanduser(dataset_path), pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-281480db3d6c>:9: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "  assert(len(cls.image_paths)>0, 'There must be at least one image for each class in the dataset')\n"
     ]
    }
   ],
   "source": [
    "def get_face_embeddings(data, model_path = \"/home/prudhvi/Desktop/Models/tf/Facenet/20180402-114759\", image_size = 160, batch_size = 64, save_to_disk = False, save_dir = None, mode = \"dataset\"):\n",
    "    \n",
    "    if save_to_disk:\n",
    "        print(\"Saving to disk!\")\n",
    "    \n",
    "    if mode == 'dataset':\n",
    "        # Check that there are at least one training image per class\n",
    "        for cls in data:\n",
    "            assert(len(cls.image_paths)>0, 'There must be at least one image for each class in the dataset')\n",
    "        \n",
    "        # Extract and show data stats\n",
    "        paths, labels = facenet.get_image_paths_and_labels(data)\n",
    "        print('Number of classes: %d' % len(data))\n",
    "        print('Number of images: %d' % len(paths))\n",
    "    elif mode == \"paths\":\n",
    "        paths = data\n",
    "    else:\n",
    "        print(\"Error! Wrong mode specified\")\n",
    "        return\n",
    "    \n",
    "    with tf.Graph().as_default():\n",
    "      \n",
    "        with tf.Session() as sess:\n",
    "            \n",
    "            np.random.seed(seed=1)\n",
    "            \n",
    "            # Load the model\n",
    "            print('Loading feature extraction model')\n",
    "            facenet.load_model(model_path)\n",
    "            \n",
    "            # Get input and output tensors\n",
    "            images_placeholder = tf.get_default_graph().get_tensor_by_name(\"input_6_2:0\")\n",
    "            embeddings = tf.get_default_graph().get_tensor_by_name(\"lambda_6_1/l2_normalize:0\")\n",
    "            embedding_size = embeddings.get_shape()[1]\n",
    "            print(\"embedding size\", embedding_size)\n",
    "            \n",
    "             # Run forward pass to calculate embeddings\n",
    "            emb_dict={}\n",
    "            print('Calculating features for images')\n",
    "            nrof_images = len(paths)\n",
    "            nrof_batches_per_epoch = int(math.ceil(1.0*nrof_images / batch_size))\n",
    "            emb_array = np.zeros((nrof_images, embedding_size))\n",
    "            print(\"Number of epochs\", nrof_batches_per_epoch)\n",
    "            for i in range(nrof_batches_per_epoch):\n",
    "                start_index = i*batch_size\n",
    "                end_index = min((i+1)*batch_size, nrof_images)\n",
    "                paths_batch = paths[start_index:end_index]\n",
    "                images = facenet.load_data(paths_batch, False, False, image_size, do_prewhiten=False)\n",
    "                # Whats a phase train placeholder??\n",
    "                feed_dict = { images_placeholder:images }\n",
    "                emb_array[start_index:end_index,:] = sess.run(embeddings, feed_dict=feed_dict)\n",
    "            \n",
    "            return emb_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading feature extraction model\n",
      "Model filename: ./train.pb\n",
      "embedding size 512\n",
      "Calculating features for images\n",
      "Number of epochs 188\n"
     ]
    }
   ],
   "source": [
    "embeddings = get_face_embeddings(paths, model_path='./train.pb', mode = \"paths\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.61483+-0.02084\n",
      "Validation rate: 0.00267+-0.00389 @ FAR=0.00100\n",
      "Area Under Curve (AUC): 0.650\n",
      "Equal Error Rate (EER): 0.390\n"
     ]
    }
   ],
   "source": [
    "tpr, fpr, accuracy, val, val_std, far = lfw.evaluate(embeddings, actual_issame, nrof_folds=10, distance_metric=1, subtract_mean=1)\n",
    "    \n",
    "print('Accuracy: %2.5f+-%2.5f' % (np.mean(accuracy), np.std(accuracy)))\n",
    "print('Validation rate: %2.5f+-%2.5f @ FAR=%2.5f' % (val, val_std, far))\n",
    "    \n",
    "auc = metrics.auc(fpr, tpr)\n",
    "print('Area Under Curve (AUC): %1.3f' % auc)\n",
    "eer = brentq(lambda x: 1. - x - interpolate.interp1d(fpr, tpr)(x), 0., 1.)\n",
    "print('Equal Error Rate (EER): %1.3f' % eer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
